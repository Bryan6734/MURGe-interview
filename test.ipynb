{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:35<00:00, 17.61s/it]\n",
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "#     You are in the living room. \n",
    "#     You see: couch, television, book.\n",
    "#     You have the following items in your inventory: .\n",
    "\n",
    "#     Valid actions include:\n",
    "#     pick up couch\n",
    "#     pick up television\n",
    "#     pick up book\n",
    "#     go to living room\n",
    "#     go to kitchen\n",
    "\n",
    "#     Q: What action should you take that is the most relevant to your goal?\n",
    "#     A: \"\"\"\n",
    "\n",
    "#     actions = [\n",
    "#     \"pick up couch\",\n",
    "#     \"pick up television\",\n",
    "#     \"pick up book\",\n",
    "#     \"go to living room\",\n",
    "#     \"go to kitchen\"\n",
    "#     ]\n",
    "\n",
    "#     # Tokenize the input prompt\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "#     # Obtain logits\n",
    "#     outputs = model(**inputs)\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     # Obtain log probabilities by applying log softmax to logits\n",
    "#     log_probs = torch.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them. You are in the living room. You see: couch, television, book. You have the following items in your inventory: .\n",
    "Valid actions include:\n",
    "pick up couch\n",
    "pick up television\n",
    "pick up book\n",
    "go to living room\n",
    "go to kitchen\n",
    "\n",
    "Action: \"\"\"\n",
    "\n",
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the living room.\n",
    "You see: couch, television, book.       \n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bedroom, go to bathroom\n",
    "\n",
    "Action: \"\"\"\n",
    "\n",
    "actions = [\n",
    "    \"pick up couch\",\n",
    "    \"pick up television\",\n",
    "    \"pick up book\",\n",
    "    \"go to living room\",\n",
    "    \"go to kitchen\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probability(prompt, action):\n",
    "    # Tokenize the prompt + action\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Get logits from the model for the prompt\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Softmax over the logits to get the probability distribution\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # Extract probabilities for each token in the action\n",
    "    action_prob = 1.0\n",
    "    for i, token_id in enumerate(action_tokens[0]):\n",
    "        action_prob *= probs[0, -(len(action_tokens[0]) - i), token_id].item()  # Prob for each token\n",
    "\n",
    "    return action_prob\n",
    "\n",
    "\n",
    "scores = []\n",
    "for action in actions:\n",
    "    score = get_action_probability(prompt, action)\n",
    "    print(f\"{action} | {score}\")\n",
    "    scores.append(score)\n",
    "\n",
    "index = scores.index(max(scores))\n",
    "print(f\"Best Action: {actions[index]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\\n\\nYou are in the living room.\\nYou see: couch, television, book.\\nYou have the following items in your inventory: .\\nValid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bedroom, go to bathroom\\n\\nAction: '\n",
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: pick up couch\n",
      "pick up couch | 3.5558075346929936e-26\n",
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: pick up television\n",
      "pick up television | 8.645185726234681e-26\n",
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: pick up book\n",
      "pick up book | 1.6957559330676202e-25\n",
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: go to living room\n",
      "go to living room | 5.250405302855485e-31\n",
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: go to kitchen\n",
      "go to kitchen | 7.268801508845875e-25\n",
      "go to kitchen\n"
     ]
    }
   ],
   "source": [
    "print(repr(prompt))\n",
    "\n",
    "def score_action(prompt: str, action: str):\n",
    "\n",
    "    print(prompt + action)\n",
    "\n",
    "    # Tokenize prompt + action, as well as action\n",
    "    input_tokens = tokenizer(prompt + action, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_tokens)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute probability distribution\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    action_score = 1.0\n",
    "    \n",
    "    for idx, action_token_id in enumerate(action_tokens[0]):\n",
    "        action_token_position = input_tokens[\"input_ids\"].shape[1] - action_tokens.shape[1] + idx\n",
    "\n",
    "        # look up the probability\n",
    "        action_probability = probs[0, action_token_position, action_token_id].item()\n",
    "        action_score *= action_probability\n",
    "        \n",
    "    return action_score\n",
    "        \n",
    "\n",
    "# Instruction, as used in the paper\n",
    "scores = []\n",
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the living room. \n",
    "You see: couch, television, book.\n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
    "\n",
    "Action: \"\"\"\n",
    "for action in actions:\n",
    "    # Probability that a skill is useful for instruction\n",
    "    score = score_action(prompt, action)\n",
    "    print(f\"{action} | {score}\")\n",
    "    scores.append(score)\n",
    "\n",
    "arg_max = actions[scores.index(max(scores))]\n",
    "print(arg_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_action(prompt: str, action: str):\n",
    "\n",
    "    # Construct the full prompt with the action\n",
    "    full_prompt = f\"{prompt} {action}\"\n",
    "\n",
    "    # Tokenize the full prompt\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Obtain logits for the entire prompt\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Obtain log probabilities\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the action tokens\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\").to(device).input_ids[0]\n",
    "    \n",
    "    # Find the starting index of the action tokens in the full input\n",
    "    num_prompt_tokens = inputs.input_ids.shape[1] - action_tokens.shape[0]\n",
    "\n",
    "    # Extract scores for each action token\n",
    "    action_scores = []\n",
    "    for idx, token_id in enumerate(action_tokens):\n",
    "        action_token_score = log_probs[0, num_prompt_tokens + idx, token_id]\n",
    "        action_scores.append(action_token_score.item())\n",
    "\n",
    "    # Compute the average score for the action\n",
    "    average_score = max(action_scores)\n",
    "\n",
    "    return average_score  # Return the list of scores for the action tokens\n",
    "\n",
    "    # # Tokenize actions (each element is a token_id, which corresponds to log_probs)\n",
    "    # action_tokens = tokenizer(action, return_tensors=\"pt\").to(device).input_ids[0]\n",
    "    # total_score = 0.0\n",
    "\n",
    "    # # Iterate through all tokens in the action\n",
    "    # for idx, token_id in enumerate(action_tokens):\n",
    "\n",
    "    #     # Tokenize the input prompt\n",
    "    #     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    #     # Obtain logits\n",
    "    #     outputs = model(**inputs)\n",
    "    #     logits = outputs.logits\n",
    "    #     # Obtain log probabilities by applying log softmax to logits\n",
    "    #     log_probs = torch.log_softmax(logits, dim=1)\n",
    "    #     # Get the number of tokens in the inputs\n",
    "    #     num_input_tokens = inputs.input_ids.shape[1]\n",
    "\n",
    "    #     # Obtain current token score from log_probabilities\n",
    "    #     action_token_score = log_probs[0, num_input_tokens + idx - 1, token_id]\n",
    "\n",
    "    #     print(\"Token score\", action_token_score)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    return action_tokens\n",
    "\n",
    "\n",
    "action_scores = {}\n",
    "for action in actions:\n",
    "    score = score_action(prompt, action)\n",
    "    action_scores[action] = score\n",
    "\n",
    "\n",
    "for action, score in action_scores.items():\n",
    "    print(f\"Action: {action}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs[0, prompt_len - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason we do prompt_len - 1 + 1 is because:\n",
    "# indexing starts at 0, so we subtract 1 from prompt_len\n",
    "# Since we are accumulating probabiltiy tokens, we need to add the i to shift it incrementally so that we are not just\n",
    "# looking at \"ap\" in \"apple\", or \"ora\" in \"orange\", for example\n",
    "\n",
    "\n",
    "    for answer in answers:\n",
    "        print(\"-----------------\")\n",
    "\n",
    "        # Note that answer_tokens is stored as [[values]] (but we only have 1 batch)\n",
    "        answer_tokens = tokenizer(answer, return_tensors=\"pt\").to(device).input_ids\n",
    "        total_log_prob = 0.0\n",
    "\n",
    "        # Iterate through all tokens in the answer token\n",
    "        # LOOK AT ANSWER:\n",
    "        print(f\"Action {answer}\")\n",
    "        for i, token_id in enumerate(answer_tokens[0]):\n",
    "            print(f\"Token Index: {i}, Token ID: {token_id}\")\n",
    "\n",
    "            \n",
    "\n",
    "            # Lookup the log probability of this token in the log_probs distribution\n",
    "            # token_log_prob = log_probs[0, index - 1, token_id]\n",
    "            # total_log_prob += token_log_prob\n",
    "            # print(f\"Current Token Log Probability: {token_log_prob}, Total Log Probability: {total_log_prob}\")\n",
    "\n",
    "\n",
    "        answer_log_probs[answer] = total_log_prob\n",
    "\n",
    "    Print out the log-probabilities for each answer\n",
    "    print(\"------------\")\n",
    "    for answer, log_prob in answer_log_probs.items():\n",
    "        print(f\"Answer: {answer}, Log Probability: {log_prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
