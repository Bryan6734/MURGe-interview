{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "torch.manual_seed(12)\n",
    "random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:40<00:00, 20.20s/it]\n",
      "c:\\Users\\Bryan Sukidi\\Projects\\interview_package_murge_ambiguity_project\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the living room. \n",
    "You see: couch, television, book.\n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
    "\n",
    "Action: \"\"\"\n",
    "\n",
    "valid_actions = [\n",
    "    \"pick up couch\",\n",
    "    \"pick up television\",\n",
    "    \"pick up book\",\n",
    "    \"go to kitchen\",\n",
    "    \"go to bathroom\",\n",
    "    \"go to bedroom\",\n",
    "]\n",
    "\n",
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the kitchen.\n",
    "You see: fork, spoon.\n",
    "You have the following items in your inventory: knife.\n",
    "Valid actions: go to bathroom, go to bedroom, go to living room    \n",
    "\n",
    "Action:\"\"\"\n",
    "\n",
    "valid_actions = [\n",
    "    \"go to bathroom\",\n",
    "    \"go to bedroom\",\n",
    "    \"go to living room\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked completion probabilities (log scale):\n",
      "\"go to living room\": -0.9896\n",
      "\"go to bathroom\": -2.3422\n",
      "\"go to bedroom\": -2.4047\n"
     ]
    }
   ],
   "source": [
    "# Define the query and options\n",
    "query = prompt\n",
    "options = valid_actions\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Calculate probability for each option\n",
    "for option in options:\n",
    "    # Encode sequences\n",
    "    prompt_action_str = f\"{query} {option}\"\n",
    "    prompt_action_tokens = tokenizer.encode(prompt_action_str, return_tensors=\"pt\")\n",
    "    \n",
    "    prompt_tokens = tokenizer.encode(query, return_tensors=\"pt\")\n",
    "    prompt_length = prompt_tokens.shape[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(prompt_action_tokens)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # get logits and logprobs\n",
    "    logits = logits[:, prompt_length-1:-1, :]\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # log_probs shape is [1, n, vocab_size]\n",
    "    # action_tokens shape is [1, n]\n",
    "    action_tokens = prompt_action_tokens[:, prompt_length:]\n",
    "    token_log_probs = log_probs[0, torch.arange(action_tokens.shape[1]), action_tokens[0]]\n",
    "    \n",
    "    sequence_log_prob = token_log_probs.sum().item()\n",
    "    results.append((option, sequence_log_prob))\n",
    "\n",
    "# Sort and print results\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nRanked completion probabilities (log scale):\")\n",
    "for option, log_prob in results:\n",
    "    print(f'\"{option}\": {log_prob:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go to living room'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32000])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs[0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "Action: go to \n",
      "------------------------------------------------------------\n",
      "'kitchen': -11.349634170532227\n",
      "action 'kitchen': -11.349634170532227\n",
      "\n",
      "'bedroom': -9.390345573425293\n",
      "action 'bedroom': -9.390345573425293\n",
      "\n",
      "'bathroom': -10.493440628051758\n",
      "action 'bathroom': -10.493440628051758\n",
      "\n",
      "------------------------------------------------------------\n",
      "Sorted Scores:\n",
      "bedroom: -9.390345573425293\n",
      "bathroom: -10.493440628051758\n",
      "kitchen: -11.349634170532227\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the living room. \n",
    "You see: couch, television, book.\n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
    "\n",
    "Action: \"\"\"\n",
    "\n",
    "valid_actions = [\n",
    "    \"pick up couch\",\n",
    "    \"pick up television\",\n",
    "    \"pick up book\",\n",
    "    \"go to kitchen\",\n",
    "    \"go to bathroom\",\n",
    "    \"go to bedroom\",\n",
    "]\n",
    "\n",
    "scores = {}\n",
    "\n",
    "print(prompt)\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "for action in valid_actions:\n",
    "    query = prompt + action\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # applied log softmax to get log probabilities (log_probs)\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "\n",
    "    # only interested in the action log probabilities, so we select the last few logits (using action token)\n",
    "    action_tokens = tokenizer.encode(action, add_special_tokens=False)\n",
    "    num_tokens = len(action_tokens)\n",
    "    print(f\"Action tokens: {num_tokens}\")\n",
    "\n",
    "    log_probs = log_probs[0, -num_tokens:, :]\n",
    "    total_token_score = 0\n",
    "    for i, token in enumerate(action_tokens):\n",
    "        print(f\"'{tokenizer.decode(token)}': {token_score}\")\n",
    "        token_score = log_probs[i][token].item()\n",
    "        total_token_score += token_score\n",
    "    \n",
    "    print(f\"action '{action}': {total_token_score}\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "    scores[action] = total_token_score\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Sorted Scores:\")\n",
    "for action, score in sorted_scores:\n",
    "    print(f\"{action}: {score}\")\n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "    # print(f\"Log probabilities for action '{action}': {log_probs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "#     You are in the living room. \n",
    "#     You see: couch, television, book.\n",
    "#     You have the following items in your inventory: .\n",
    "\n",
    "#     Valid actions include:\n",
    "#     pick up couch\n",
    "#     pick up television\n",
    "#     pick up book\n",
    "#     go to living room\n",
    "#     go to kitchen\n",
    "\n",
    "#     Q: What action should you take that is the most relevant to your goal?\n",
    "#     A: \"\"\"\n",
    "\n",
    "#     actions = [\n",
    "#     \"pick up couch\",\n",
    "#     \"pick up television\",\n",
    "#     \"pick up book\",\n",
    "#     \"go to living room\",\n",
    "#     \"go to kitchen\"\n",
    "#     ]\n",
    "\n",
    "#     # Tokenize the input prompt\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "#     # Obtain logits\n",
    "#     outputs = model(**inputs)\n",
    "#     logits = outputs.logits\n",
    "\n",
    "#     # Obtain log probabilities by applying log softmax to logits\n",
    "#     log_probs = torch.log_softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the kitchen.\n",
    "You see: knife, fork, spoon.\n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up knife, pick up fork, pick up spoon\n",
    "\n",
    "Action: \"\"\"\n",
    "\n",
    "valid_actions = [\n",
    "    \"pick up knife\",\n",
    "    \"pick up fork\",\n",
    "    \"pick up spoon\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pick up knife - -10.764559537172318\n",
      "pick up fork - -10.66055477783084\n",
      "pick up spoon - -10.227042868733406\n",
      "Best Action: pick up spoon\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for tracking the best action\n",
    "best_action = None\n",
    "best_log_sum = float('-inf')  # Initialize to negative infinity\n",
    "\n",
    "# Iterate over valid actions\n",
    "for action in valid_actions:\n",
    "    # Prepare the input sequence\n",
    "    input_tokens = tokenizer.encode(prompt + action, add_special_tokens=False, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Initialize log sum for this action\n",
    "    log_sum = 0\n",
    "    \n",
    "    # Tokenize the action to get individual tokens\n",
    "    action_tokens = tokenizer.encode(action, add_special_tokens=False, return_tensors=\"pt\").to(device)\n",
    "    for i in range(action_tokens.shape[1]):\n",
    "        # Predict with the given model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tokens)\n",
    "            logit_predictions = outputs.logits\n",
    "\n",
    "        # Extract the log probability of the most recently added token\n",
    "        last_token_logit = logit_predictions[0, -1, :]\n",
    "        last_token_log_probs = torch.nn.functional.log_softmax(last_token_logit, dim=-1)\n",
    "        log_token_prob = last_token_log_probs[action_tokens[0, i]].item()\n",
    "        log_sum += log_token_prob\n",
    "\n",
    "        # Incrementally add an output token to the current sequence\n",
    "        last_token = action_tokens[:, i:i+1]\n",
    "        input_tokens = torch.cat([input_tokens, last_token], dim=1)\n",
    "\n",
    "    print(f\"{action} - {log_sum}\")\n",
    "    # Check if the current action is the best one so far\n",
    "    if log_sum > best_log_sum:\n",
    "        best_log_sum = log_sum\n",
    "        best_action = action\n",
    "\n",
    "# Output the best action\n",
    "print(f\"Best Action: {best_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_probability(prompt, action):\n",
    "    # Tokenize the prompt + action\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Get logits from the model for the prompt\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Softmax over the logits to get the probability distribution\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # Extract probabilities for each token in the action\n",
    "    action_prob = 1.0\n",
    "    for i, token_id in enumerate(action_tokens[0]):\n",
    "        action_prob *= probs[0, -(len(action_tokens[0]) - i), token_id].item()  # Prob for each token\n",
    "\n",
    "    return action_prob\n",
    "\n",
    "\n",
    "scores = []\n",
    "for action in actions:\n",
    "    score = get_action_probability(prompt, action)\n",
    "    print(f\"{action} | {score}\")\n",
    "    scores.append(score)\n",
    "\n",
    "index = scores.index(max(scores))\n",
    "print(f\"Best Action: {actions[index]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: pick up couch, Log Probability Score: -29.797097206115723\n",
      "Action: pick up television, Log Probability Score: -30.571372032165527\n",
      "Action: pick up book, Log Probability Score: -29.78604030609131\n",
      "Action: go to kitchen, Log Probability Score: -27.17565393447876\n",
      "Action: go to bedroom, Log Probability Score: -25.06926918029785\n",
      "Action: go to bathroom, Log Probability Score: -25.485308170318604\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store scores\n",
    "action_scores = {}\n",
    "\n",
    "# Score each valid action\n",
    "for action in valid_actions:\n",
    "    # Create input for the model\n",
    "    input_text = f\"{prompt} {action}\"\n",
    "    input_tokens = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tokens)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the log probabilities of the last token\n",
    "    last_token_logits = logits[0, -1, :]\n",
    "    last_token_log_probs = torch.nn.functional.log_softmax(last_token_logits, dim=-1)\n",
    "\n",
    "    # Get the token ID of the last token in the action\n",
    "    action_tokens = tokenizer.encode(action, add_special_tokens=False)\n",
    "    action_log_prob = sum(last_token_log_probs[token].item() for token in action_tokens)\n",
    "\n",
    "    # Store the total log probability for the action\n",
    "    action_scores[action] = action_log_prob\n",
    "\n",
    "# Output the action scores\n",
    "for action, score in action_scores.items():\n",
    "    print(f\"Action: {action}, Log Probability Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_action(prompt: str, action: str):\n",
    "\n",
    "\n",
    "    # Tokenize prompt + action, as well as action\n",
    "    input_tokens = tokenizer(prompt + action, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_tokens)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute probability distribution\n",
    "    probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "    action_score = 0.0\n",
    "    \n",
    "    print(f\"action = {action}\")\n",
    "    print(f\"action token = {action_tokens[0]}\")\n",
    "    for idx, action_token_id in enumerate(action_tokens[0]):\n",
    "        action_token_position = input_tokens[\"input_ids\"].shape[1] - action_tokens.shape[1] + idx \n",
    "        # look up the probability\n",
    "        print(f\"action token position = {action_token_position}\")\n",
    "        action_probability = probs[0, action_token_position, action_token_id].item()\n",
    "        print(f\"action probability = {action_probability}\")\n",
    "        action_score += action_probability\n",
    "        \n",
    "    return action_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\\n\\nYou are in the living room. \\nYou see: couch, television, book.\\nYou have the following items in your inventory: .\\nValid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\\n\\nThe knife is in the kitchen.\\n\\nAction: '"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pick up couch',\n",
       " 'pick up television',\n",
       " 'pick up book',\n",
       " 'go to kitchen',\n",
       " 'go to bedroom',\n",
       " 'go to bathroom']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = pick up couch\n",
      "action token = tensor([    1,  3088,   582, 18602])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -12.847025871276855\n",
      "action token position = 112\n",
      "action probability = -9.812251091003418\n",
      "action token position = 113\n",
      "action probability = -12.791942596435547\n",
      "action = pick up television\n",
      "action token = tensor([   1, 3088,  582, 8575])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -12.847025871276855\n",
      "action token position = 112\n",
      "action probability = -9.812251091003418\n",
      "action token position = 113\n",
      "action probability = -11.886855125427246\n",
      "action = pick up book\n",
      "action token = tensor([   1, 3088,  582, 1820])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -12.847025871276855\n",
      "action token position = 112\n",
      "action probability = -9.812251091003418\n",
      "action token position = 113\n",
      "action probability = -10.689133644104004\n",
      "action = go to kitchen\n",
      "action token = tensor([   1,  576,  298, 6132])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -10.878698348999023\n",
      "action token position = 112\n",
      "action probability = -8.469297409057617\n",
      "action token position = 113\n",
      "action probability = -12.599283218383789\n",
      "action = go to bedroom\n",
      "action token = tensor([   1,  576,  298, 9384])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -10.878698348999023\n",
      "action token position = 112\n",
      "action probability = -8.469297409057617\n",
      "action token position = 113\n",
      "action probability = -9.655280113220215\n",
      "action = go to bathroom\n",
      "action token = tensor([    1,   576,   298, 10629])\n",
      "action token position = 110\n",
      "action probability = -23.85727310180664\n",
      "action token position = 111\n",
      "action probability = -10.878698348999023\n",
      "action token position = 112\n",
      "action probability = -8.469297409057617\n",
      "action token position = 113\n",
      "action probability = -11.10077953338623\n"
     ]
    }
   ],
   "source": [
    "for action in actions:\n",
    "    score_action(prompt, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\\n\\nYou are in the living room. \\nYou see: couch, television, book.\\nYou have the following items in your inventory: .\\nValid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\\n\\nThe knife is in the kitchen.\\n\\nAction: '\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: pick up couch\n",
      "-\n",
      "action = pick up couch\n",
      "action token = tensor([    1,  3088,   582, 18602])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 2.633949861774454e-06\n",
      "action token position = 112\n",
      "action probability = 5.4776381148258224e-05\n",
      "action token position = 113\n",
      "action probability = 2.7831085844809422e-06\n",
      "pick up couch | 1.748432676364631e-26\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: pick up television\n",
      "-\n",
      "action = pick up television\n",
      "action token = tensor([   1, 3088,  582, 8575])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 2.633949861774454e-06\n",
      "action token position = 112\n",
      "action probability = 5.4776381148258224e-05\n",
      "action token position = 113\n",
      "action probability = 6.880250111862551e-06\n",
      "pick up television | 4.322380443300403e-26\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: pick up book\n",
      "-\n",
      "action = pick up book\n",
      "action token = tensor([   1, 3088,  582, 1820])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 2.633949861774454e-06\n",
      "action token position = 112\n",
      "action probability = 5.4776381148258224e-05\n",
      "action token position = 113\n",
      "action probability = 2.2791247829445638e-05\n",
      "pick up book | 1.431814865662497e-25\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: go to kitchen\n",
      "-\n",
      "action = go to kitchen\n",
      "action token = tensor([   1,  576,  298, 6132])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 1.8855645976145752e-05\n",
      "action token position = 112\n",
      "action probability = 0.00020981226407457143\n",
      "action token position = 113\n",
      "action probability = 3.374433845237945e-06\n",
      "go to kitchen | 5.812876914777729e-25\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: go to bedroom\n",
      "-\n",
      "action = go to bedroom\n",
      "action token = tensor([   1,  576,  298, 9384])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 1.8855645976145752e-05\n",
      "action token position = 112\n",
      "action probability = 0.00020981226407457143\n",
      "action token position = 113\n",
      "action probability = 6.408627814380452e-05\n",
      "go to bedroom | 1.1039648837740883e-23\n",
      "Untokenized text: You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
      "\n",
      "You are in the living room. \n",
      "You see: couch, television, book.\n",
      "You have the following items in your inventory: .\n",
      "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
      "\n",
      "The knife is in the kitchen.\n",
      "\n",
      "Action: go to bathroom\n",
      "-\n",
      "action = go to bathroom\n",
      "action token = tensor([    1,   576,   298, 10629])\n",
      "len input = 114\n",
      "action token position = 110\n",
      "action probability = 4.3542957434139495e-11\n",
      "action token position = 111\n",
      "action probability = 1.8855645976145752e-05\n",
      "action token position = 112\n",
      "action probability = 0.00020981226407457143\n",
      "action token position = 113\n",
      "action probability = 1.5100553355296142e-05\n",
      "go to bathroom | 2.601255855800627e-24\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[1.748432676364631e-26, 4.322380443300403e-26, 1.431814865662497e-25, 5.812876914777729e-25, 1.1039648837740883e-23, 2.601255855800627e-24] is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m---> 54\u001b[0m arg_max \u001b[38;5;241m=\u001b[39m actions[\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal action = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: [1.748432676364631e-26, 4.322380443300403e-26, 1.431814865662497e-25, 5.812876914777729e-25, 1.1039648837740883e-23, 2.601255855800627e-24] is not in list"
     ]
    }
   ],
   "source": [
    "print(repr(prompt))\n",
    "\n",
    "def score_action(prompt: str, action: str):\n",
    "\n",
    "\n",
    "    # Tokenize prompt + action, as well as action\n",
    "    input_tokens = tokenizer(prompt + action, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    untokenized_text = tokenizer.decode(input_tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    print(\"Untokenized text:\", untokenized_text)\n",
    "    print(\"-\")\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_tokens)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute probability distribution\n",
    "    probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "    action_score = 1.0\n",
    "    \n",
    "    print(f\"action = {action}\")\n",
    "    print(f\"action token = {action_tokens[0]}\")\n",
    "    print(f\"len input = {input_tokens.input_ids.shape[1]}\")\n",
    "    for idx, action_token_id in enumerate(action_tokens[0]):\n",
    "        action_token_position = input_tokens[\"input_ids\"].shape[1] - action_tokens.shape[1] + idx \n",
    "        # look up the probability\n",
    "        print(f\"action token position = {action_token_position}\")\n",
    "        action_probability = probs[0, action_token_position, action_token_id].item()\n",
    "        print(f\"action probability = {action_probability}\")\n",
    "        action_score *= action_probability\n",
    "        \n",
    "    return action_score\n",
    "        \n",
    "\n",
    "# Instruction, as used in the paper\n",
    "scores = []\n",
    "prompt = \"\"\"You are an intelligent robot. Your goal is to drop a knife in the living room. Knife is in the kitchen. You can navigate the environment, pick up items, and drop them.\n",
    "\n",
    "You are in the living room. \n",
    "You see: couch, television, book.\n",
    "You have the following items in your inventory: .\n",
    "Valid actions: pick up couch, pick up television, pick up book, go to kitchen, go to bathroom, go to bedroom\n",
    "\n",
    "The knife is in the kitchen.\n",
    "\n",
    "Action: \"\"\"\n",
    "for action in actions:\n",
    "    # Probability that a skill is useful for instruction\n",
    "    score = score_action(prompt, action)\n",
    "    print(f\"{action} | {score}\")\n",
    "    scores.append(score)\n",
    "\n",
    "arg_max = actions[scores.index((scores))]\n",
    "print(f\"final action = {arg_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-47.34778928756714"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_action(prompt: str, action: str) -> float:\n",
    "\n",
    "    # Tokenize prompt + action, as well as action\n",
    "    input_tokens = tokenizer(prompt + action, return_tensors=\"pt\")\n",
    "    action_tokens = tokenizer(action, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "    # Compute logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_tokens)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute probability distribution\n",
    "    probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "    action_score = 0\n",
    "\n",
    "    # Calculate the score for the action\n",
    "    for idx, action_token_id in enumerate(action_tokens[0]):\n",
    "        action_token_position = input_tokens[\"input_ids\"].shape[1] - action_tokens.shape[1] + idx\n",
    "        action_probability = probs[0, action_token_position, action_token_id].item()\n",
    "        action_score += action_probability\n",
    "\n",
    "    return action_score\n",
    "\n",
    "score_action(prompt, \"go to k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46.714717388153076"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_action(prompt, \"go to bathroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs[0, prompt_len - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go to bedroom'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_constrained_response(prompt: str, valid_actions: list[str]) -> str:\n",
    "    scores = []\n",
    "    \n",
    "    for action in valid_actions:\n",
    "        # Combine prompt with action\n",
    "        input_text = prompt + action\n",
    "        \n",
    "        # Tokenize\n",
    "        input_tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
    "        \n",
    "        # Get model output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**input_tokens)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # Calculate probability\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get the token IDs for the action\n",
    "        action_token_ids = tokenizer(action)[\"input_ids\"]\n",
    "        \n",
    "        # Access the last token's position for the action in the input\n",
    "        action_prob = 1.0\n",
    "        for idx, action_token_id in enumerate(action_token_ids):\n",
    "            action_token_position = input_tokens[\"input_ids\"].shape[1] - len(action_token_ids) + idx\n",
    "            action_probability = probs[0, action_token_position, action_token_id].item()\n",
    "            action_prob *= action_probability  # Combine probabilities\n",
    "            \n",
    "        scores.append(action_prob)\n",
    "    \n",
    "    # Select action with highest score\n",
    "    best_action = valid_actions[scores.index(max(scores))]\n",
    "    return best_action\n",
    "\n",
    "# Example usage\n",
    "generate_constrained_response(prompt, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m untokenized_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mtokens\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntokenized text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, untokenized_text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "untokenized_text = tokenizer.decode(tokens[\"input_ids\"][0], skip_special_tokens=True)\n",
    "print(\"Untokenized text:\", untokenized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tokens = tokenizer.encode(\"He likes pizza with ugly women and toes\", return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(combined_tokens)\n",
    "    logits = outputs.logits  # shape: (batch_size, sequence_length, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token IDs for \"pepperoni\" and \"and\", \"pizza\"\n",
    "token_ids = tokenizer.encode(\"ugly women and toes\", return_tensors='pt')\n",
    "# Get logits for the last tokens\n",
    "relevant_logits = logits[0, -len(token_ids[0]):]  # Get the last len(token_ids) logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.nn.functional.softmax(relevant_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32000])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the indices for the tokens\n",
    "indices = token_ids[0].tolist()\n",
    "\n",
    "# Compute the joint probability\n",
    "joint_probability = 1.0\n",
    "for i in range(len(indices)):\n",
    "    joint_probability += probabilities[i, indices[i]].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0004383147687157"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.107884229026856e-28"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_probability # joint_probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
